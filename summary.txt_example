＜Directory Structure＞

=== Tree for . ===
.
├── .gitignore
├── Cargo.toml
├── README.md
├── src
│   └── main.rs
└── temp
    ├── summary.txt
    └── workplan.txt

＜File Contents＞

--------------------------------------------------------------------------------
.gitignore (in .):
--------------------------------------------------------------------------------
# Created by https://www.toptal.com/developers/gitignore/api/rust
# Edit at https://www.toptal.com/developers/gitignore?templates=rust

### Rust ###
# Generated by Cargo
# will have compiled files and executables
debug/
target/

# Remove Cargo.lock from gitignore if creating an executable, leave it for libraries
# More information here https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html
Cargo.lock

# These are backup files generated by rustfmt
**/*.rs.bk

# MSVC Windows builds of rustc generate these, which store debugging information
*.pdb

# End of https://www.toptal.com/developers/gitignore/api/rust

.clinerules

--------------------------------------------------------------------------------
Cargo.toml (in .):
--------------------------------------------------------------------------------
[package]
name = "oreuit"
version = "0.1.0"
edition = "2021"
authors = ["Name"]
rust-version = "1.70"

[dependencies]
clap = { version = "4.1", features = ["derive"] }
walkdir = "2.3"
encoding_rs = "0.8"
arboard = { version = "3.4.1", optional = true }
lazy_static = "1.4.0"

[features]
default = []
clipboard = ["dep:arboard"]


--------------------------------------------------------------------------------
README.md (in .):
--------------------------------------------------------------------------------
# oreuit

- **oreuit** is a tool that generates a text report summarizing the file structure and contents within specified directories. Inspired by [uithub](https://uithub.com/).
- It allows visualization of directory trees and bulk viewing of file contents for codebases without repositories, such as those not hosted on GitHub.

# Installation

## Requirements

- [Rust](https://www.rust-lang.org/) installed (version 1.70 or higher recommended)

## Installation Steps

1.  **Clone the Repository or Download the Code**
    Obtain the source code of this tool from GitHub or other sources.

    ```bash
    git clone https://github.com/yuki-inaho/uithub_like_text_generator.git # Use HTTPS or SSH URL as appropriate
    cd uithub_like_text_generator
    ```

2.  **Build**
    Execute the following command within the project directory to create a release build.

    ```bash
    # Standard build (without clipboard support)
    cargo build --release

    # Build with clipboard support (if you need the -c option)
    # cargo build --release --features clipboard
    ```

    If you plan to use the `-c, --clipboard` option, uncomment and run the second build command.

3.  **Place the Executable**
    After the build completes, the executable will be generated at `./target/release/oreuit`.
    Add it to your system's PATH or specify the execution path as needed.

# Usage

The basic usage involves specifying the target directory/directories and options when running the tool. Below are the main command-line options and their descriptions.

## Available Options

- `-d, --directory <DIRECTORIES>`
  Specify the directory or directories (comma-separated) to explore. If not specified, the current directory (`.`) is used. (Example: `-d src,tests`)

- `-e, --extensions <EXTENSIONS>`
  Provide a comma-separated list of allowed file extensions.

  - If the value starts with `+,`, the specified extensions are **added** to the default list. (Example: `-e +,.json,.vue` adds `.json` and `.vue` to the default list.)
  - Otherwise, the specified list **overwrites** the default list. (Example: `-e .py,.js` uses only `.py` and `.js`.)
  - If not specified, the default list is used.
    **Default:** `.txt`, `.md`, `.py`, `.js`, `.java`, `.cpp`, `.c`, `.cs`, `.rb`, `.go`, `.rs`, `.hpp`, `.ts`, `.tsx`, `.d.ts`, `.jsx`, `.toml`
    **Note:** `.json` is not included by default. To include it, use `-e +,.json`.
    **Note:** Files without extensions (e.g., `.gitignore`, `Makefile`, `Dockerfile`, `LICENSE`, `README`, `.gitattributes`, `justfile`) are allowed by default unless explicitly ignored.

- `-i, --ignore-extensions <EXTENSIONS>`
  Provide a comma-separated list of file extensions to ignore. (Example: `-i .lock,.md`)
  The default value is:

  ```
  .bin,.zip,.tar,.gz,.7z,.rar,.exe,.dll,.so,.dylib,.a,.lib,.obj,.o,.class,.jar,.war,.ear,.ipynb,.jpg,.jpeg,.png,.gif
  ```

- `-o, --output <OUTPUT>`
  Specify the output file name. The default is `summary.txt`.

- `-c, --clipboard`
  Instead of writing the output to a file, copy the results to the clipboard.
  **Note:** Requires the tool to be built with the `clipboard` feature enabled (see Installation section).

- `--ignore-dirs <DIRS>`
  Provide a comma-separated list of directory names to ignore.

  - If the value starts with `+,`, the specified directories are **added** to the default ignore list. (Example: `--ignore-dirs +,my_temp,build2` adds `my_temp` and `build2` to the default ignore list.)
  - Otherwise, the specified list **overwrites** the default list.
  - If not specified, the default list is used.
    **Default:** `.git`, `.vscode`, `target`, `node_modules`, `__pycache__`, `.idea`, `build`, `dist`, `.ruff_cache`, `.cache`, `.tox`, `.nox`, `.pytest_cache`, `htmlcov`, `instance`, `.env`, `.venv`, `env`, `venv`, `ENV`, `site`, `.mypy_cache`, `debug` etc.

- `--ignore-files <FILENAMES>`
  Provide a comma-separated list of **filenames** to ignore. (Example: `--ignore-files setup.py,config.local.toml`)
  This overrides allowed/ignored extensions but is **overridden by** `--whitelist-filenames`. If a file is in the whitelist, it will be included even if it's listed here. Defaults to empty.

- `--max-size <MAX_SIZE>`
  Specify the maximum file size (in bytes) for reading file contents. The default is `10485760` (10MB).
  Files exceeding the specified size will have their content extraction skipped.

- `-w, --whitelist-filenames <FILENAMES>`
  Specify a comma-separated list of filenames that are always included, regardless of their file extension or location. (Example: `Dockerfile,Makefile`)
  **Default:** `Dockerfile,Makefile,justfile`

---

## Command and Output Examples

Example commands:

```bash
# Scan the current directory, ignoring temp and adding .json files
./target/release/oreuit -d . --ignore-dirs +,temp -e +,.json -o summary.txt

# Scan the src directory, using only .py and .js extensions
./target/release/oreuit -d src -e .py,.js -o summary_src.txt

# Scan the current directory, ignoring only the 'build' directory (overwrites default ignore list)
./target/release/oreuit -d . --ignore-dirs build -o summary_build_only.txt

# Scan the current directory, ignoring specific setup files
./target/release/oreuit -d . --ignore-files setup.py,conftest.py -o summary_no_setup.txt
```


--------------------------------------------------------------------------------
src/main.rs (in .):
--------------------------------------------------------------------------------
use clap::Parser;
use encoding_rs::SHIFT_JIS;
use std::collections::HashSet;
use std::error::Error;
use std::fs;
use std::io::Read;
use std::path::{Path, PathBuf};
#[macro_use]
extern crate lazy_static;

use walkdir::WalkDir;

/// Tool to summarize directory structure and file contents
#[derive(Parser, Debug)]
#[clap(
    author,
    version,
    about = "A tool to summarize directory structure and file contents (similar to uithub)"
)]
struct Args {
    /// Directories to explore (comma-separated, default is the current directory)
    #[clap(short = 'd', long = "directory", default_value = ".")]
    directories: String,

    /// Allowed file extensions (comma-separated, e.g., .txt,.md,.py).
    /// Prefix with '+,' to ADD to the default list (e.g., +,.json,.vue).
    /// If not specified, the default list is used.
    #[clap(short = 'e', long = "extensions")]
    extensions: Option<String>,

    /// File extensions to ignore (comma-separated, e.g., .bin,.zip,...). If empty, no extensions are ignored
    #[clap(
        short = 'i',
        long = "ignore-extensions",
        default_value = ".bin,.zip,.tar,.gz,.7z,.rar,.exe,.dll,.so,.dylib,.a,.lib,.obj,.o,.class,.jar,.war,.ear,.ipynb,.jpg,.jpeg,.png,.gif"
    )]
    ignore_extensions: String,

    /// Filenames to ignore (comma-separated, e.g., setup.py,config.toml). Overrides allowed extensions but not whitelist.
    #[clap(long = "ignore-files", default_value = "")]
    ignore_files: String,

    /// Output file name (default is summary.txt)
    #[clap(short = 'o', long = "output", default_value = "summary.txt")]
    output: String,

    /// Maximum file size to read (in bytes, default is 10485760 = 10MB)
    #[clap(long = "max-size", default_value = "10485760")]
    max_size: u64,

    /// Copy output to clipboard instead of writing to a file
    #[clap(short = 'c', long = "clipboard")]
    clipboard: bool,

    /// Directory names to ignore (comma-separated, e.g., .git,node_modules,__pycache__, etc.)
    /// Prefix with '+,' to ADD to the default list (e.g., +,my_temp,build2).
    #[clap(long = "ignore-dirs")]
    ignore_dirs: Option<String>,

    /// Filenames to whitelist (comma-separated, e.g., Dockerfile,Makefile). These are always included.
    #[clap(
        short = 'w',
        long = "whitelist-filenames",
        default_value = "Dockerfile,Makefile,justfile"
    )]
    whitelist_filenames: String,
}

/// Determines if a file is binary by checking for NUL bytes in the first 1024 bytes
fn is_binary(file_path: &Path) -> bool {
    if let Ok(mut file) = fs::File::open(file_path) {
        let mut buffer = [0u8; 1024];
        if let Ok(n) = file.read(&mut buffer) {
            return buffer[..n].iter().any(|&b| b == 0);
        }
    }
    true
}

/// Attempts to read a file as UTF-8, and if it fails, tries to decode using SHIFT_JIS.
/// If both attempts fail, returns "[Cannot decode file content]".
fn read_file_contents(file_path: &Path) -> String {
    match fs::read_to_string(file_path) {
        Ok(text) => text,
        Err(_) => match fs::read(file_path) {
            Ok(bytes) => {
                let (cow, _, had_errors) = SHIFT_JIS.decode(&bytes);
                if had_errors {
                    "[Cannot decode file content]".to_string()
                } else {
                    cow.into_owned()
                }
            }
            Err(_) => "[Cannot decode file content]".to_string(),
        },
    }
}

/// Recursively searches the specified directory and lists files that
/// - Match allowed extensions OR are whitelisted filenames
/// - Do not have ignored extensions
/// - Are not ignored filenames
/// Files within ignored directories are not searched.
fn collect_files(
    directory: &Path,
    allowed: &HashSet<String>,
    ignore_exts: &HashSet<String>,
    ignore_dirs: &HashSet<String>,
    whitelist_filenames: &HashSet<String>,
    ignore_files: &HashSet<String>,
) -> Vec<PathBuf> {
    let walker = WalkDir::new(directory).into_iter().filter_entry(|e| {
        if e.file_type().is_dir() {
            if let Some(name) = e.file_name().to_str() {
                return !ignore_dirs.contains(&name.to_string());
            }
        }
        true
    });
    let mut files = Vec::new();
    for entry in walker.filter_map(|e| e.ok()) {
        if entry.file_type().is_file() {
            let path = entry.path();
            let file_name_os = entry.file_name();
            let file_name = file_name_os.to_string_lossy();
            if whitelist_filenames.contains(file_name.as_ref()) {
                files.push(path.to_path_buf());
                continue;
            }
            if ignore_files.contains(file_name.as_ref()) {
                continue;
            }
            if let Some(ext) = path.extension().and_then(|e| e.to_str()) {
                let ext_formatted = format!(".{}", ext.to_lowercase());
                if ignore_exts.contains(&ext_formatted) {
                    continue;
                }
                if !allowed.is_empty() && !allowed.contains(&ext_formatted) {
                    continue;
                }
            } else {
                let allowed_no_ext = [
                    "Makefile", "Dockerfile", "LICENSE", "README", ".gitignore", ".gitattributes", "justfile"
                ];
                if !allowed.is_empty() && !allowed_no_ext.contains(&file_name.as_ref()) {
                    continue;
                }
            }
            files.push(path.to_path_buf());
        }
    }
    files.sort();
    files
}

/// Generates a tree structure of the specified directory.
fn build_tree(
    directory: &Path,
    allowed: &HashSet<String>,
    ignore_exts: &HashSet<String>,
    ignore_dirs: &HashSet<String>,
    whitelist_filenames: &HashSet<String>,
    ignore_files: &HashSet<String>,
) -> String {
    let base_name = match directory.file_name().and_then(|s| s.to_str()) {
        Some(s) => s.to_string(),
        None => directory.to_string_lossy().into_owned(),
    };
    let mut lines = vec![base_name];
    build_tree_helper(
        directory,
        "",
        allowed,
        ignore_exts,
        ignore_dirs,
        whitelist_filenames,
        ignore_files,
        &mut lines,
    );
    lines.join("\n")
}

/// Helper function that recursively traverses the directory structure and builds the tree string
fn build_tree_helper(
    path: &Path,
    prefix: &str,
    allowed: &HashSet<String>,
    ignore_exts: &HashSet<String>,
    ignore_dirs: &HashSet<String>,
    whitelist_filenames: &HashSet<String>,
    ignore_files: &HashSet<String>,
    lines: &mut Vec<String>,
) {
    let mut entries: Vec<fs::DirEntry> = match fs::read_dir(path) {
        Ok(iter) => iter.filter_map(|e| e.ok()).collect(),
        Err(_) => return,
    };
    entries.sort_by_key(|e| e.file_name());
    let mut filtered_entries = Vec::new();
    for entry in entries {
        let entry_path = entry.path();
        let file_name_os = entry.file_name();
        let name_buf = file_name_os.to_string_lossy().to_string();
        let name = &name_buf;
        if entry_path.is_dir() {
            if ignore_dirs.contains(name) {
                continue;
            }
            filtered_entries.push((entry, true));
        } else if entry_path.is_file() {
            if whitelist_filenames.contains(name) {
                filtered_entries.push((entry, false));
                continue;
            }
            if ignore_files.contains(name) {
                continue;
            }
            if let Some(ext) = entry_path.extension().and_then(|e| e.to_str()) {
                let ext_formatted = format!(".{}", ext.to_lowercase());
                if ignore_exts.contains(&ext_formatted) {
                    continue;
                }
                if !allowed.is_empty() && !allowed.contains(&ext_formatted) {
                    continue;
                }
            } else {
                let allowed_no_ext = [
                    "Makefile", "Dockerfile", "LICENSE", "README", ".gitignore", ".gitattributes", "justfile"
                ];
                if !allowed.is_empty() && !allowed_no_ext.contains(&name.as_ref()) {
                    continue;
                }
            }
            filtered_entries.push((entry, false));
        }
    }
    let count = filtered_entries.len();
    for (i, (entry, is_dir)) in filtered_entries.into_iter().enumerate() {
        let is_last = i == count - 1;
        let connector = if is_last { "└── " } else { "├── " };
        let name_buf = entry.file_name().to_string_lossy().to_string();
        let name = &name_buf;
        lines.push(format!("{}{}{}", prefix, connector, name));
        if is_dir {
            let new_prefix = if is_last {
                format!("{}    ", prefix)
            } else {
                format!("{}│   ", prefix)
            };
            build_tree_helper(
                &entry.path(),
                &new_prefix,
                allowed,
                ignore_exts,
                ignore_dirs,
                whitelist_filenames,
                ignore_files,
                lines,
            );
        }
    }
}

lazy_static! {
    static ref DEFAULT_ALLOWED_EXTENSIONS: HashSet<String> = [
        ".txt", ".md", ".py", ".js", ".java", ".cpp", ".c", ".cs", ".rb", ".go", ".rs", ".hpp",
        ".ts", ".tsx", ".d.ts", ".jsx", ".toml",
    ]
    .iter()
    .map(|s| s.to_string())
    .collect();
    static ref DEFAULT_IGNORE_DIRS: HashSet<String> = [
        ".git",
        ".vscode",
        "target",
        "node_modules",
        "__pycache__",
        ".idea",
        "build",
        "dist",
        ".ruff_cache",
        ".cache",
        ".tox",
        ".nox",
        ".pytest_cache",
        "htmlcov",
        "instance",
        ".env",
        ".venv",
        "env",
        "venv",
        "ENV",
        "site",
        ".mypy_cache",
        "debug",
    ]
    .iter()
    .map(|s| s.to_string())
    .collect();
}

fn main() -> Result<(), Box<dyn Error>> {
    let args = Args::parse();

    let directories: Vec<PathBuf> = args
        .directories
        .split(',')
        .filter_map(|s| {
            let s = s.trim();
            if s.is_empty() {
                None
            } else {
                let path = PathBuf::from(s);
                if !path.exists() {
                    eprintln!("Warning: Directory not found, skipping: {}", path.display());
                    None
                } else if !path.is_dir() {
                    eprintln!(
                        "Warning: Path is not a directory, skipping: {}",
                        path.display()
                    );
                    None
                } else {
                    Some(path)
                }
            }
        })
        .collect();

    if directories.is_empty() {
        eprintln!("Error: No valid directories specified or found.");
        return Ok(());
    }

    let allowed: HashSet<String> = match &args.extensions {
        None => DEFAULT_ALLOWED_EXTENSIONS.clone(),
        Some(val) => {
            let val = val.trim();
            if val.is_empty() {
                DEFAULT_ALLOWED_EXTENSIONS.clone()
            } else if val.starts_with("+,") {
                let mut set = DEFAULT_ALLOWED_EXTENSIONS.clone();
                for s in val.trim_start_matches("+,").split(',') {
                    let s = s.trim().to_lowercase();
                    if s.is_empty() {
                        continue;
                    }
                    if s.starts_with('.') {
                        set.insert(s);
                    } else {
                        set.insert(format!(".{}", s));
                    }
                }
                set
            } else {
                val.split(',')
                    .filter_map(|s| {
                        let s = s.trim().to_lowercase();
                        if s.is_empty() {
                            None
                        } else if s.starts_with('.') {
                            Some(s)
                        } else {
                            Some(format!(".{}", s))
                        }
                    })
                    .collect()
            }
        }
    };

    let ignore_exts: HashSet<String> = args
        .ignore_extensions
        .split(',')
        .filter_map(|s| {
            let s = s.trim().to_lowercase();
            if s.is_empty() {
                None
            } else if s.starts_with('.') {
                Some(s)
            } else {
                Some(format!(".{}", s))
            }
        })
        .collect();

    let ignore_dirs: HashSet<String> = match &args.ignore_dirs {
        None => DEFAULT_IGNORE_DIRS.clone(),
        Some(val) => {
            let val = val.trim();
            if val.is_empty() {
                DEFAULT_IGNORE_DIRS.clone()
            } else if val.starts_with("+,") {
                let mut set = DEFAULT_IGNORE_DIRS.clone();
                for s in val.trim_start_matches("+,").split(',') {
                    let s = s.trim().to_string();
                    if s.is_empty() {
                        continue;
                    }
                    set.insert(s);
                }
                set
            } else {
                val.split(',')
                    .filter_map(|s| {
                        let s = s.trim().to_string();
                        if s.is_empty() {
                            None
                        } else {
                            Some(s)
                        }
                    })
                    .collect()
            }
        }
    };

    let whitelist_filenames: HashSet<String> = args
        .whitelist_filenames
        .split(',')
        .filter_map(|s| {
            let s = s.trim().to_string();
            if s.is_empty() {
                None
            } else {
                Some(s)
            }
        })
        .collect();

    let ignore_files: HashSet<String> = args
        .ignore_files
        .split(',')
        .filter_map(|s| {
            let s = s.trim().to_string();
            if s.is_empty() { None } else { Some(s) }
        })
        .collect();

    let mut all_tree_text = String::new();
    let mut all_file_contents = String::new();

    for dir in &directories {
        let dir_name_for_header = match dir.file_name().and_then(|s| s.to_str()) {
            Some(s) => s.to_string(),
            None => dir.to_string_lossy().into_owned(),
        };

        let tree_text = build_tree(
            dir,
            &allowed,
            &ignore_exts,
            &ignore_dirs,
            &whitelist_filenames,
            &ignore_files,
        );

        all_tree_text.push_str(&format!(
            "=== Tree for {} ===\n{}\n\n",
            dir_name_for_header, tree_text
        ));

        let files = collect_files(
            dir,
            &allowed,
            &ignore_exts,
            &ignore_dirs,
            &whitelist_filenames,
            &ignore_files,
        );

        for file in files {
            let relative_path = file.strip_prefix(dir).unwrap_or(&file).to_string_lossy();

            let header = format!(
                "--------------------------------------------------------------------------------\n{} (in {}):\n--------------------------------------------------------------------------------\n",
                relative_path, dir_name_for_header
            );
            let size = fs::metadata(&file).map(|m| m.len()).unwrap_or(0);
            let content = if size > args.max_size {
                "[File size exceeds limit; skipped]\n".to_string()
            } else if is_binary(&file) {
                "[Binary file skipped]\n".to_string()
            } else {
                read_file_contents(&file)
            };
            all_file_contents.push_str(&header);
            all_file_contents.push_str(&content);
            all_file_contents.push_str("\n\n");
        }
    }

    if !all_tree_text.is_empty() {
        all_tree_text.pop();
        all_tree_text.pop();
    }
    if !all_file_contents.is_empty() {
        all_file_contents.pop();
        all_file_contents.pop();
    }

    let output_text = format!(
        "＜Directory Structure＞\n\n{}\n\n＜File Contents＞\n\n{}",
        all_tree_text, all_file_contents
    );

    if args.clipboard {
        #[cfg(feature = "clipboard")]
        {
            // Assumes arboard is set as optional = true and configured in features in Cargo.toml
            match arboard::Clipboard::new() {
                Ok(mut clipboard) => {
                    clipboard.set_text(output_text)?;
                    println!("Output content has been copied to the clipboard.");
                }
                Err(e) => {
                    eprintln!(
                        "Failed to access the clipboard: {}. Try writing to a file instead.",
                        e
                    );
                }
            }
        }
        #[cfg(not(feature = "clipboard"))]
        {
            eprintln!("Clipboard feature is not enabled. Please compile with '--features clipboard' or use the -o option to write to a file.");
        }
    } else {
        fs::write(&args.output, output_text)?;
        println!("Output completed: {}", args.output);
    }
    Ok(())
}


--------------------------------------------------------------------------------
temp/summary.txt (in .):
--------------------------------------------------------------------------------
＜Directory Structure＞

=== Tree for . ===
.
├── src
│   └── main.rs
├── .gitignore
├── Cargo.toml
└── README.md

＜File Contents＞

--------------------------------------------------------------------------------
.gitignore (in .):
--------------------------------------------------------------------------------
# Created by https://www.toptal.com/developers/gitignore/api/rust
# Edit at https://www.toptal.com/developers/gitignore?templates=rust

### Rust ###
# Generated by Cargo
# will have compiled files and executables
debug/
target/

# Remove Cargo.lock from gitignore if creating an executable, leave it for libraries
# More information here https://doc.rust-lang.org/cargo/guide/cargo-toml-vs-cargo-lock.html
Cargo.lock

# These are backup files generated by rustfmt
**/*.rs.bk

# MSVC Windows builds of rustc generate these, which store debugging information
*.pdb

# End of https://www.toptal.com/developers/gitignore/api/rust



--------------------------------------------------------------------------------
Cargo.toml (in .):
--------------------------------------------------------------------------------
[package]
name = "oreuit"
version = "0.1.0"
edition = "2021"
authors = ["Name"]
rust-version = "1.70"

[dependencies]
clap = { version = "4.1", features = ["derive"] }
walkdir = "2.3"
encoding_rs = "0.8"
arboard = { version = "3.4.1", optional = true }
lazy_static = "1.4.0"

[features]
default = []
clipboard = ["dep:arboard"]


--------------------------------------------------------------------------------
README.md (in .):
--------------------------------------------------------------------------------
# oreuit

- **oreuit** is a tool that generates a text report summarizing the file structure and contents within specified directories. Inspired by [uithub](https://uithub.com/).
- It allows visualization of directory trees and bulk viewing of file contents for codebases without repositories, such as those not hosted on GitHub.

# Installation

## Requirements

- [Rust](https://www.rust-lang.org/) installed (version 1.70 or higher recommended)

## Installation Steps

1.  **Clone the Repository or Download the Code**
    Obtain the source code of this tool from GitHub or other sources.

    ```bash
    git clone https://github.com/yuki-inaho/uithub_like_text_generator.git # Use HTTPS or SSH URL as appropriate
    cd uithub_like_text_generator
    ```

2.  **Build**
    Execute the following command within the project directory to create a release build.

    ```bash
    # Standard build (without clipboard support)
    cargo build --release

    # Build with clipboard support (if you need the -c option)
    # cargo build --release --features clipboard
    ```

    If you plan to use the `-c, --clipboard` option, uncomment and run the second build command.

3.  **Place the Executable**
    After the build completes, the executable will be generated at `./target/release/oreuit`.
    Add it to your system's PATH or specify the execution path as needed.

# Usage

The basic usage involves specifying the target directory/directories and options when running the tool. Below are the main command-line options and their descriptions.

## Available Options

- `-d, --directory <DIRECTORIES>`
  Specify the directory or directories (comma-separated) to explore. If not specified, the current directory (`.`) is used. (Example: `-d src,tests`)

- `-e, --extensions <EXTENSIONS>`
  Provide a comma-separated list of allowed file extensions.

  - If the value starts with `+,`, the specified extensions are **added** to the default list. (Example: `-e +,.json,.vue` adds `.json` and `.vue` to the default list.)
  - Otherwise, the specified list **overwrites** the default list. (Example: `-e .py,.js` uses only `.py` and `.js`.)
  - If not specified, the default list is used.
    **Default:** `.txt`, `.md`, `.py`, `.js`, `.java`, `.cpp`, `.c`, `.cs`, `.rb`, `.go`, `.rs`, `.hpp`, `.ts`, `.tsx`, `.d.ts`, `.jsx`, `.toml`
    **Note:** `.json` is not included by default. To include it, use `-e +,.json`.
    **Note:** Files without extensions (e.g., `.gitignore`, `Makefile`, `Dockerfile`, `LICENSE`, `README`, `.gitattributes`) are allowed by default unless explicitly ignored.

- `-i, --ignore-extensions <EXTENSIONS>`
  Provide a comma-separated list of file extensions to ignore. (Example: `-i .lock,.md`)
  The default value is:

  ```
  .bin,.zip,.tar,.gz,.7z,.rar,.exe,.dll,.so,.dylib,.a,.lib,.obj,.o,.class,.jar,.war,.ear,.ipynb,.jpg,.jpeg,.png,.gif
  ```

- `-o, --output <OUTPUT>`
  Specify the output file name. The default is `summary.txt`.

- `-c, --clipboard`
  Instead of writing the output to a file, copy the results to the clipboard.

  **Note:** Requires the tool to be built with the `clipboard` feature enabled (see Installation section).

- `--ignore-dirs <DIRS>`
  Provide a comma-separated list of directory names to ignore.

  - If the value starts with `+,`, the specified directories are **added** to the default ignore list. (Example: `--ignore-dirs +,my_temp,build2` adds `my_temp` and `build2` to the default ignore list.)
  - Otherwise, the specified list **overwrites** the default list.
  - If not specified, the default list is used.
    **Default:** `.git`, `.vscode`, `target`, `node_modules`, `__pycache__`, `.idea`, `build`, `dist`, `.ruff_cache`

- `--max-size <MAX_SIZE>`
  Specify the maximum file size (in bytes) for reading file contents. The default is `10485760` (10MB).
  Files exceeding the specified size will have their content extraction skipped.

- `-w, --whitelist-filenames <FILENAMES>`
  Specify a comma-separated list of filenames that are always included, regardless of their file extension or location. (Example: `Dockerfile,Makefile`)

---

## Command and Output Examples

Example commands:

```bash
# Scan the current directory, ignoring temp and adding .json files
./target/release/oreuit -d . --ignore-dirs +,temp -e +,.json -o summary.txt

# Scan the src directory, using only .py and .js extensions
./target/release/oreuit -d src -e .py,.js -o summary_src.txt

# Scan the current directory, ignoring only the 'build' directory (overwrites default ignore list)
./target/release/oreuit -d . --ignore-dirs build -o summary_build_only.txt
```


--------------------------------------------------------------------------------
src/main.rs (in .):
--------------------------------------------------------------------------------
use clap::Parser;
use encoding_rs::SHIFT_JIS;
use std::collections::HashSet;
use std::error::Error;
use std::fs;
use std::io::Read;
use std::path::{Path, PathBuf};
#[macro_use]
extern crate lazy_static;

use walkdir::WalkDir;

/// Tool to summarize directory structure and file contents
#[derive(Parser, Debug)]
#[clap(
    author,
    version,
    about = "A tool to summarize directory structure and file contents (similar to uithub)"
)]
struct Args {
    /// Directories to explore (comma-separated, default is the current directory)
    #[clap(short = 'd', long = "directory", default_value = ".")]
    directories: String,

    /// Allowed file extensions (comma-separated, e.g., .txt,.md,.py).
    /// Prefix with '+,' to ADD to the default list (e.g., +,.json,.vue).
    /// If not specified, the default list is used.
    #[clap(short = 'e', long = "extensions")]
    extensions: Option<String>,

    /// File extensions to ignore (comma-separated, e.g., .bin,.zip,...). If empty, no extensions are ignored
    #[clap(
        short = 'i',
        long = "ignore-extensions",
        default_value = ".bin,.zip,.tar,.gz,.7z,.rar,.exe,.dll,.so,.dylib,.a,.lib,.obj,.o,.class,.jar,.war,.ear,.ipynb,.jpg,.jpeg,.png,.gif"
    )]
    ignore_extensions: String,

    /// Output file name (default is summary.txt)
    #[clap(short = 'o', long = "output", default_value = "summary.txt")]
    output: String,

    /// Maximum file size to read (in bytes, default is 10485760 = 10MB)
    #[clap(long = "max-size", default_value = "10485760")]
    max_size: u64,

    /// Copy output to clipboard instead of writing to a file
    #[clap(short = 'c', long = "clipboard")]
    clipboard: bool,

    /// Directory names to ignore (comma-separated, e.g., .git,node_modules,__pycache__, etc.)
    /// Prefix with '+,' to ADD to the default list (e.g., +,my_temp,build2).
    #[clap(long = "ignore-dirs")]
    ignore_dirs: Option<String>,

    /// Filenames to whitelist (comma-separated, e.g., Dockerfile,Makefile). These are always included.
    #[clap(
        short = 'w',
        long = "whitelist-filenames",
        default_value = "Dockerfile,Makefile,justfile"
    )]
    whitelist_filenames: String,
}

/// Determines if a file is binary by checking for NUL bytes in the first 1024 bytes
fn is_binary(file_path: &Path) -> bool {
    if let Ok(mut file) = fs::File::open(file_path) {
        let mut buffer = [0u8; 1024];
        if let Ok(n) = file.read(&mut buffer) {
            return buffer[..n].iter().any(|&b| b == 0);
        }
    }
    true
}

/// Attempts to read a file as UTF-8, and if it fails, tries to decode using SHIFT_JIS.
/// If both attempts fail, returns "[Cannot decode file content]".
fn read_file_contents(file_path: &Path) -> String {
    match fs::read_to_string(file_path) {
        Ok(text) => text,
        Err(_) => match fs::read(file_path) {
            Ok(bytes) => {
                let (cow, _, had_errors) = SHIFT_JIS.decode(&bytes);
                if had_errors {
                    "[Cannot decode file content]".to_string()
                } else {
                    cow.into_owned()
                }
            }
            Err(_) => "[Cannot decode file content]".to_string(),
        },
    }
}

/// Recursively searches the specified directory and lists files that
/// - Match allowed extensions
/// - Do not have ignored extensions
/// - Are in the whitelist_filenames (if any)
/// Files within ignored directories are not searched.
fn collect_files(
    directory: &Path,
    allowed: &HashSet<String>,
    ignore: &HashSet<String>,
    ignore_dirs: &HashSet<String>,
    whitelist_filenames: &HashSet<String>,
) -> Vec<PathBuf> {
    let walker = WalkDir::new(directory).into_iter().filter_entry(|e| {
        if e.file_type().is_dir() {
            if let Some(name) = e.file_name().to_str() {
                return !ignore_dirs.contains(&name.to_string());
            }
        }
        true
    });

    let mut files = Vec::new();
    for entry in walker.filter_map(|e| e.ok()) {
        if entry.file_type().is_file() {
            let file_name = entry.file_name().to_string_lossy();
            let is_whitelisted = whitelist_filenames.contains(file_name.as_ref());

            if !is_whitelisted {
                if let Some(ext) = entry.path().extension().and_then(|e| e.to_str()) {
                    let ext_formatted = format!(".{}", ext.to_lowercase());
                    if !allowed.is_empty() && !allowed.contains(&ext_formatted) {
                        continue;
                    }
                    if ignore.contains(&ext_formatted) {
                        continue;
                    }
                } else {
                    // Allow filenames consisting only of alphanumeric characters and symbols (e.g., .gitignore, Makefile, LICENSE) even without an extension
                    let fname = entry
                        .path()
                        .file_name()
                        .and_then(|f| f.to_str())
                        .unwrap_or("");
                    let allowed_no_ext = [
                        "Makefile",
                        "Dockerfile",
                        "LICENSE",
                        "README",
                        ".gitignore",
                        ".gitattributes",
                    ];
                    if !allowed.is_empty() && !allowed_no_ext.contains(&fname) {
                        continue;
                    }
                }
            }
            files.push(entry.path().to_path_buf());
        }
    }

    files.sort_by_key(|e| e.file_name().map(|s| s.to_os_string()));
    files
}

/// Generates a tree structure of the specified directory.
fn build_tree(
    directory: &Path,
    allowed: &HashSet<String>,
    ignore: &HashSet<String>,
    ignore_dirs: &HashSet<String>,
    whitelist_filenames: &HashSet<String>,
) -> String {
    let base_name = match directory.file_name().and_then(|s| s.to_str()) {
        Some(s) => s.to_string(),
        None => directory.to_string_lossy().into_owned(), // Convert to String using .into_owned()
    };
    let mut lines = vec![base_name];
    build_tree_helper(
        directory,
        "",
        allowed,
        ignore,
        ignore_dirs,
        whitelist_filenames,
        &mut lines,
    );
    lines.join("\n")
}

/// Helper function that recursively traverses the directory structure and builds the tree string
fn build_tree_helper(
    path: &Path,
    prefix: &str,
    allowed: &HashSet<String>,
    ignore: &HashSet<String>,
    ignore_dirs: &HashSet<String>,
    whitelist_filenames: &HashSet<String>,
    lines: &mut Vec<String>,
) {
    let mut entries: Vec<fs::DirEntry> = match fs::read_dir(path) {
        Ok(iter) => iter.filter_map(|e| e.ok()).collect(),
        Err(_) => return,
    };
    entries.sort_by_key(|e| e.file_name());

    let mut dirs = Vec::new();
    let mut files = Vec::new();
    for entry in entries {
        let entry_path = entry.path();
        let name = entry.file_name().into_string().unwrap_or_default();

        if entry_path.is_dir() {
            if ignore_dirs.contains(&name) {
                continue;
            }
            dirs.push(entry_path.clone()); // PathBuf型で格納
        } else if entry_path.is_file() {
            let is_whitelisted = whitelist_filenames.contains(&name);
            if !is_whitelisted {
                if let Some(ext_os) = entry_path.extension() {
                    if let Some(ext) = ext_os.to_str() {
                        let ext_formatted = format!(".{}", ext.to_lowercase());
                        if !allowed.is_empty() && !allowed.contains(&ext_formatted) {
                            continue;
                        }
                        if ignore.contains(&ext_formatted) {
                            continue;
                        }
                    }
                } else {
                    let fname = entry_path
                        .file_name()
                        .and_then(|f| f.to_str())
                        .unwrap_or("");
                    let allowed_no_ext = [
                        "Makefile",
                        "Dockerfile",
                        "LICENSE",
                        "README",
                        ".gitignore",
                        ".gitattributes",
                    ];
                    if !allowed.is_empty() && !allowed_no_ext.contains(&fname) {
                        continue;
                    }
                }
            }
            files.push(entry_path.clone()); // PathBuf型で格納
        }
    }

    let mut all_entries = Vec::new();
    for d in dirs {
        all_entries.push((d, true));
    }
    for f in files {
        all_entries.push((f, false));
    }

    let count = all_entries.len();
    for (i, (entry, is_dir)) in all_entries.into_iter().enumerate() {
        let is_last = i == count - 1;
        let connector = if is_last { "└── " } else { "├── " };
        let name = entry
            .file_name()
            .and_then(|f| f.to_str())
            .unwrap_or("")
            .to_string();
        lines.push(format!("{}{}{}", prefix, connector, name));

        if is_dir {
            let new_prefix = if is_last {
                format!("{}    ", prefix)
            } else {
                format!("{}│   ", prefix)
            };
            build_tree_helper(
                &entry,
                &new_prefix,
                allowed,
                ignore,
                ignore_dirs,
                whitelist_filenames,
                lines,
            );
        }
    }
}

lazy_static! {
    static ref DEFAULT_ALLOWED_EXTENSIONS: HashSet<String> = [
        ".txt", ".md", ".py", ".js", ".java", ".cpp", ".c", ".cs", ".rb", ".go", ".rs", ".hpp",
        ".ts", ".tsx", ".d.ts", ".jsx", ".toml",
    ]
    .iter()
    .map(|s| s.to_string())
    .collect();
    static ref DEFAULT_IGNORE_DIRS: HashSet<String> = [
        ".git",
        ".vscode",
        "target",
        "node_modules",
        "__pycache__",
        ".idea",
        "build",
        "dist",
        ".ruff_cache",
        ".cache",
        ".tox",
        ".nox",
        ".pytest_cache",
        "htmlcov",
        "instance",
        ".env",
        ".venv",
        "env",
        "venv",
        "ENV",
        "site",
        ".mypy_cache",
        "debug",
    ]
    .iter()
    .map(|s| s.to_string())
    .collect();
}

fn main() -> Result<(), Box<dyn Error>> {
    let args = Args::parse();

    let directories: Vec<PathBuf> = args
        .directories
        .split(',')
        .filter_map(|s| {
            let s = s.trim();
            if s.is_empty() {
                None
            } else {
                let path = PathBuf::from(s);
                if !path.exists() {
                    eprintln!("Warning: Directory not found, skipping: {}", path.display());
                    None
                } else if !path.is_dir() {
                    eprintln!(
                        "Warning: Path is not a directory, skipping: {}",
                        path.display()
                    );
                    None
                } else {
                    Some(path)
                }
            }
        })
        .collect();

    if directories.is_empty() {
        eprintln!("Error: No valid directories specified or found.");
        return Ok(());
    }

    let allowed: HashSet<String> = match &args.extensions {
        None => DEFAULT_ALLOWED_EXTENSIONS.clone(),
        Some(val) => {
            let val = val.trim();
            if val.is_empty() {
                DEFAULT_ALLOWED_EXTENSIONS.clone()
            } else if val.starts_with("+,") {
                let mut set = DEFAULT_ALLOWED_EXTENSIONS.clone();
                for s in val.trim_start_matches("+,").split(',') {
                    let s = s.trim().to_lowercase();
                    if s.is_empty() {
                        continue;
                    }
                    if s.starts_with('.') {
                        set.insert(s);
                    } else {
                        set.insert(format!(".{}", s));
                    }
                }
                set
            } else {
                val.split(',')
                    .filter_map(|s| {
                        let s = s.trim().to_lowercase();
                        if s.is_empty() {
                            None
                        } else if s.starts_with('.') {
                            Some(s)
                        } else {
                            Some(format!(".{}", s))
                        }
                    })
                    .collect()
            }
        }
    };

    let ignore: HashSet<String> = args
        .ignore_extensions
        .split(',')
        .filter_map(|s| {
            let s = s.trim().to_lowercase();
            if s.is_empty() {
                None
            } else if s.starts_with('.') {
                Some(s)
            } else {
                Some(format!(".{}", s))
            }
        })
        .collect();

    let ignore_dirs: HashSet<String> = match &args.ignore_dirs {
        None => DEFAULT_IGNORE_DIRS.clone(),
        Some(val) => {
            let val = val.trim();
            if val.is_empty() {
                DEFAULT_IGNORE_DIRS.clone()
            } else if val.starts_with("+,") {
                let mut set = DEFAULT_IGNORE_DIRS.clone();
                for s in val.trim_start_matches("+,").split(',') {
                    let s = s.trim().to_string();
                    if s.is_empty() {
                        continue;
                    }
                    set.insert(s);
                }
                set
            } else {
                val.split(',')
                    .filter_map(|s| {
                        let s = s.trim().to_string();
                        if s.is_empty() {
                            None
                        } else {
                            Some(s)
                        }
                    })
                    .collect()
            }
        }
    };

    let whitelist_filenames: HashSet<String> = args
        .whitelist_filenames
        .split(',')
        .filter_map(|s| {
            let s = s.trim().to_string();
            if s.is_empty() {
                None
            } else {
                Some(s)
            }
        })
        .collect();

    let mut all_tree_text = String::new();
    let mut all_file_contents = String::new();

    for dir in &directories {
        let dir_name_for_header = match dir.file_name().and_then(|s| s.to_str()) {
            Some(s) => s.to_string(),
            None => dir.to_string_lossy().into_owned(), // Convert to String using .into_owned()
        };

        let tree_text = build_tree(dir, &allowed, &ignore, &ignore_dirs, &whitelist_filenames);

        // Pass String to format! (it will be referenced automatically)
        all_tree_text.push_str(&format!(
            "=== Tree for {} ===\n{}\n\n",
            dir_name_for_header, tree_text
        ));

        let files = collect_files(dir, &allowed, &ignore, &ignore_dirs, &whitelist_filenames);

        for file in files {
            let relative_path = file.strip_prefix(dir).unwrap_or(&file).to_string_lossy();

            // Pass String to format!
            let header = format!(
                "--------------------------------------------------------------------------------\n{} (in {}):\n--------------------------------------------------------------------------------\n",
                relative_path, dir_name_for_header // Use dir_name_for_header (String) here as well
            );
            let size = fs::metadata(&file).map(|m| m.len()).unwrap_or(0);
            let content = if size > args.max_size {
                "[File size exceeds limit; skipped]\n".to_string()
            } else if is_binary(&file) {
                "[Binary file skipped]\n".to_string()
            } else {
                read_file_contents(&file)
            };
            all_file_contents.push_str(&header);
            all_file_contents.push_str(&content);
            all_file_contents.push_str("\n\n");
        }
    }

    if !all_tree_text.is_empty() {
        all_tree_text.pop();
        all_tree_text.pop();
    }
    if !all_file_contents.is_empty() {
        all_file_contents.pop();
        all_file_contents.pop();
    }

    let output_text = format!(
        "＜Directory Structure＞\n\n{}\n\n＜File Contents＞\n\n{}",
        all_tree_text, all_file_contents
    );

    if args.clipboard {
        #[cfg(feature = "clipboard")]
        {
            // Assumes arboard is set as optional = true and configured in features in Cargo.toml
            match arboard::Clipboard::new() {
                Ok(mut clipboard) => {
                    clipboard.set_text(output_text)?;
                    println!("Output content has been copied to the clipboard.");
                }
                Err(e) => {
                    eprintln!(
                        "Failed to access the clipboard: {}. Try writing to a file instead.",
                        e
                    );
                }
            }
        }
        #[cfg(not(feature = "clipboard"))]
        {
            eprintln!("Clipboard feature is not enabled. Please compile with '--features clipboard' or use the -o option to write to a file.");
        }
    } else {
        fs::write(&args.output, output_text)?;
        println!("Output completed: {}", args.output);
    }
    Ok(())
}


--------------------------------------------------------------------------------
temp/workplan.txt (in .):
--------------------------------------------------------------------------------
はい、承知いたしました。
デフォルト許可拡張子の見直し（`.json` 除外）と、デフォルトへの追加指定方法の変更（`+,{追加項目}`形式）を反映した目的・作業計画を作成します。

---

### 目的

1.  **TypeScript サポートの最適化:**
    *   デフォルトで処理対象とするファイル拡張子リスト (`default_allowed`) に、主要なTypeScript関連拡張子 (`.ts`, `.tsx`, `.d.ts`, `.jsx`) を含めます。
    *   一方で、汎用的なデータ形式である `.json` は、常に含めたいとは限らないため、デフォルトリストからは除外し、必要に応じてユーザーが追加できるようにします。
2.  **設定の明確性と利便性の向上:**
    *   コマンドライン引数で許可する拡張子 (`-e, --extensions`) や無視するディレクトリ (`--ignore-dirs`) を指定する際に、デフォルトリストへの追加意図をより明確にするため、**`+,{追加項目}`** という形式を採用します (例: `-e +,.json,.vue`)。これにより、単なる値 (`.json`) と追加指定 (`+,.json`) を明確に区別し、ユーザーの意図しない上書きを防ぎます。

### 作業計画

1.  **デフォルト許可拡張子の確定:**
    *   `main` 関数内で定義されているデフォルトの許可拡張子リスト（例: `DEFAULT_EXTENSIONS_STR` 定数または `default_allowed` の初期化箇所）を以下のように確定します。
        *   **含める:** `.txt`, `.md`, `.py`, `.js`, `.java`, `.cpp`, `.c`, `.cs`, `.rb`, `.go`, `.rs`, `.hpp`, **`.ts`, `.tsx`, `.d.ts`, `.jsx`**
        *   **含めない (除外):** `.json` (その他、以前のデフォルトリストに含まれていて不要なものがあればそれも)

2.  **コマンドライン引数処理の変更:**
    *   **`Args` 構造体の修正:**
        *   （前回の提案通り）`extensions` と `ignore_dirs` の型を `Option<String>` にし、`default_value` を削除します。
        *   `extensions` と `ignore_dirs` のヘルプメッセージ (`///` コメント) を更新し、値の先頭に **`+,`** を付けることでデフォルトリストへの追加が可能になることを明記します (例: `Prefix with '+,' to ADD... (e.g., +,.json,.vue)` )。
    *   **`main` 関数のロジック修正:**
        *   `allowed` (許可拡張子セット) の生成ロジックを変更します。
            *   `args.extensions` が `None` の場合は、ステップ1で確定した新しいデフォルト拡張子リストを使用します。
            *   `args.extensions` が `Some(value)` の場合:
                *   `value` が **`+,`** で始まるかチェックします (`strip_prefix("+,"`)。
                *   **`+,`** で始まる場合: デフォルトリストをコピーし、**`+,`** 以降のカンマ区切りの指定された拡張子を追加します。
                *   **`+,`** で始まらない場合: 指定された拡張子のみでリストを構成（上書き）します。
                *   指定された拡張子に `.` がなければ自動的に付与する処理は維持します。
        *   `ignore_dirs` (無視ディレクトリセット) の生成ロジックも同様に変更します。
            *   `args.ignore_dirs` が `None` の場合は、デフォルトの無視ディレクトリリストを使用します。
            *   `args.ignore_dirs` が `Some(value)` の場合:
                *   **`+,`** プレフィックスの有無に基づき、デフォルトへの追加、またはリストの上書きを行います。

3.  **ドキュメント (README.md) の更新:**
    *   `-e, --extensions` オプションの説明を更新し、ステップ1で確定した新しいデフォルト拡張子リストと、**`+,`** プレフィックスによる追加機能について記述します。
    *   `--ignore-dirs` オプションの説明を更新し、**`+,`** プレフィックスによる追加機能について記述します。
    *   必要に応じて、使用例 (Usage Example) も更新します（例: `-e +,.json` でJSONを追加する例など）。

4.  **動作確認:**
    *   コードをビルドし、以下のケースで意図通りに動作するかを確認します。
        *   オプション指定なし（新しいデフォルト値が適用され、`.json` が含まれないこと）。
        *   `-e +,.json` / `--ignore-dirs +,.my_temp` （`+,`形式での追加機能のテスト）。
        *   `-e .py,.js` / `--ignore-dirs node_modules` （上書き機能のテスト、`+,`がない場合）。
        *   `-e +foo` (不正な形式、上書きとして扱われるか、あるいはエラーとするか実装方針によるが、意図した動作か確認）。
        *   TypeScriptファイルを含むプロジェクトで実行し、`.ts`, `.tsx` などがデフォルトで処理されることを確認します。
        *   `.json` ファイルを含むプロジェクトで実行し、デフォルトでは処理されず、`-e +,.json` を付けた場合に処理されることを確認します。

---